\hypertarget{a00074}{}\subsection{The u\+IP T\+C\+P/\+IP stack}
\label{a00074}\index{The u\+I\+P T\+C\+P/\+I\+P stack@{The u\+I\+P T\+C\+P/\+I\+P stack}}


The u\+IP T\+C\+P/\+IP stack provides Internet communication abilities to Contiki.  


\subsubsection*{Modules}
\begin{DoxyCompactItemize}
\item 
\hyperlink{a00070}{6\+Lo\+W\+P\+A\+N implementation}
\begin{DoxyCompactList}\small\item\em 6lowpan is a Working Group in I\+E\+TF which defines the use of I\+Pv6 on I\+E\+EE 802.\+15.\+4 links. \end{DoxyCompactList}\item 
\hyperlink{a00075}{u\+I\+P I\+Pv6 specific features}
\begin{DoxyCompactList}\small\item\em The u\+IP I\+Pv6 stack provides new Internet communication abilities to Contiki. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsubsection{Detailed Description}
The u\+IP T\+C\+P/\+IP stack provides Internet communication abilities to Contiki. 

\hypertarget{a00074_uip-introduction}{}\subsubsection{u\+I\+P introduction}\label{a00074_uip-introduction}
The u\+IP T\+C\+P/\+IP stack is intended to make it possible to communicate using the T\+C\+P/\+IP protocol suite even on small 8-\/bit micro-\/controllers. Despite being small and simple, u\+IP do not require their peers to have complex, full-\/size stacks, but can communicate with peers running a similarly light-\/weight stack. The code size is on the order of a few kilobytes and R\+AM usage can be configured to be as low as a few hundred bytes.

u\+IP can be found at the u\+IP web page\+: \href{http://www.sics.se/~adam/uip/}{\tt http\+://www.\+sics.\+se/$\sim$adam/uip/}

\begin{DoxySeeAlso}{See also}
tcpip 

\hyperlink{a00075}{u\+IP I\+Pv6 specific features} and \hyperlink{a00070}{6\+Lo\+W\+P\+A\+N implementation} 

u\+IP Compile-\/time configuration options 

u\+IP Run-\/time configuration functions 

u\+IP initialization functions 

u\+IP device driver interface and u\+IP variables used by device drivers 

u\+IP functions called from application programs (see below) and the protosockets A\+PI and their underlying \hyperlink{a00066}{protothreads}
\end{DoxySeeAlso}
\hypertarget{a00074_uIPIntroduction}{}\subsubsection{Introduction}\label{a00074_uIPIntroduction}
With the success of the Internet, the T\+C\+P/\+IP protocol suite has become a global standard for communication. T\+C\+P/\+IP is the underlying protocol used for web page transfers, e-\/mail transmissions, file transfers, and peer-\/to-\/peer networking over the Internet. For embedded systems, being able to run native T\+C\+P/\+IP makes it possible to connect the system directly to an intranet or even the global Internet. Embedded devices with full T\+C\+P/\+IP support will be first-\/class network citizens, thus being able to fully communicate with other hosts in the network.

Traditional T\+C\+P/\+IP implementations have required far too much resources both in terms of code size and memory usage to be useful in small 8 or 16-\/bit systems. Code size of a few hundred kilobytes and R\+AM requirements of several hundreds of kilobytes have made it impossible to fit the full T\+C\+P/\+IP stack into systems with a few tens of kilobytes of R\+AM and room for less than 100 kilobytes of code.

The u\+IP implementation is designed to have only the absolute minimal set of features needed for a full T\+C\+P/\+IP stack. It can only handle a single network interface and contains the IP, I\+C\+MP, U\+DP and T\+CP protocols. u\+IP is written in the C programming language.

Many other T\+C\+P/\+IP implementations for small systems assume that the embedded device always will communicate with a full-\/scale T\+C\+P/\+IP implementation running on a workstation-\/class machine. Under this assumption, it is possible to remove certain T\+C\+P/\+IP mechanisms that are very rarely used in such situations. Many of those mechanisms are essential, however, if the embedded device is to communicate with another equally limited device, e.\+g., when running distributed peer-\/to-\/peer services and protocols. u\+IP is designed to be R\+FC compliant in order to let the embedded devices to act as first-\/class network citizens. The u\+IP T\+C\+P/\+IP implementation that is not tailored for any specific application.\hypertarget{a00074_uip-tcpip}{}\subsubsection{T\+C\+P/\+I\+P Communication}\label{a00074_uip-tcpip}
The full T\+C\+P/\+IP suite consists of numerous protocols, ranging from low level protocols such as A\+RP which translates IP addresses to M\+AC addresses, to application level protocols such as S\+M\+TP that is used to transfer e-\/mail. The u\+IP is mostly concerned with the T\+CP and IP protocols and upper layer protocols will be referred to as \char`\"{}the
application\char`\"{}. Lower layer protocols are often implemented in hardware or firmware and will be referred to as \char`\"{}the network device\char`\"{} that are controlled by the network device driver.

T\+CP provides a reliable byte stream to the upper layer protocols. It breaks the byte stream into appropriately sized segments and each segment is sent in its own IP packet. The IP packets are sent out on the network by the network device driver. If the destination is not on the physically connected network, the IP packet is forwarded onto another network by a router that is situated between the two networks. If the maximum packet size of the other network is smaller than the size of the IP packet, the packet is fragmented into smaller packets by the router. If possible, the size of the T\+CP segments are chosen so that fragmentation is minimized. The final recipient of the packet will have to reassemble any fragmented IP packets before they can be passed to higher layers.

The formal requirements for the protocols in the T\+C\+P/\+IP stack is specified in a number of R\+FC documents published by the Internet Engineering Task Force, I\+E\+TF. Each of the protocols in the stack is defined in one more R\+FC documents and R\+F\+C1122 collects all requirements and updates the previous R\+F\+Cs.

The R\+F\+C1122 requirements can be divided into two categories; those that deal with the host to host communication and those that deal with communication between the application and the networking stack. An example of the first kind is \char`\"{}\+A T\+C\+P M\+U\+S\+T be able to receive a T\+C\+P
option in any segment\char`\"{} and an example of the second kind is "There M\+U\+ST be a mechanism for reporting soft T\+CP error conditions to the application." A T\+C\+P/\+IP implementation that violates requirements of the first kind may not be able to communicate with other T\+C\+P/\+IP implementations and may even lead to network failures. Violation of the second kind of requirements will only affect the communication within the system and will not affect host-\/to-\/host communication.

In u\+IP, all R\+FC requirements that affect host-\/to-\/host communication are implemented. However, in order to reduce code size, we have removed certain mechanisms in the interface between the application and the stack, such as the soft error reporting mechanism and dynamically configurable type-\/of-\/service bits for T\+CP connections. Since there are only very few applications that make use of those features they can be removed without loss of generality.\hypertarget{a00074_mainloop}{}\subsubsection{Main Control Loop}\label{a00074_mainloop}
The u\+IP stack can be run either as a task in a multitasking system, or as the main program in a singletasking system. In both cases, the main control loop does two things repeatedly\+:


\begin{DoxyItemize}
\item Check if a packet has arrived from the network.
\item Check if a periodic timeout has occurred.
\end{DoxyItemize}

If a packet has arrived, the input handler function, uip\+\_\+input(), should be invoked by the main control loop. The input handler function will never block, but will return at once. When it returns, the stack or the application for which the incoming packet was intended may have produced one or more reply packets which should be sent out. If so, the network device driver should be called to send out these packets.

Periodic timeouts are used to drive T\+CP mechanisms that depend on timers, such as delayed acknowledgments, retransmissions and round-\/trip time estimations. When the main control loop infers that the periodic timer should fire, it should invoke the timer handler function uip\+\_\+periodic(). Because the T\+C\+P/\+IP stack may perform retransmissions when dealing with a timer event, the network device driver should called to send out the packets that may have been produced.\hypertarget{a00074_arch}{}\subsubsection{Architecture Specific Functions}\label{a00074_arch}
u\+IP requires a few functions to be implemented specifically for the architecture on which u\+IP is intended to run. These functions should be hand-\/tuned for the particular architecture, but generic C implementations are given as part of the u\+IP distribution.\hypertarget{a00074_checksums}{}\paragraph{Checksum Calculation}\label{a00074_checksums}
The T\+CP and IP protocols implement a checksum that covers the data and header portions of the T\+CP and IP packets. Since the calculation of this checksum is made over all bytes in every packet being sent and received it is important that the function that calculates the checksum is efficient. Most often, this means that the checksum calculation must be fine-\/tuned for the particular architecture on which the u\+IP stack runs.

While u\+IP includes a generic checksum function, it also leaves it open for an architecture specific implementation of the two functions uip\+\_\+ipchksum() and uip\+\_\+tcpchksum(). The checksum calculations in those functions can be written in highly optimized assembler rather than generic C code.\hypertarget{a00074_longarith}{}\paragraph{32-\/bit Arithmetic}\label{a00074_longarith}
The T\+CP protocol uses 32-\/bit sequence numbers, and a T\+CP implementation will have to do a number of 32-\/bit additions as part of the normal protocol processing. Since 32-\/bit arithmetic is not natively available on many of the platforms for which u\+IP is intended, u\+IP leaves the 32-\/bit additions to be implemented by the architecture specific module and does not make use of any 32-\/bit arithmetic in the main code base.

While u\+IP implements a generic 32-\/bit addition, there is support for having an architecture specific implementation of the uip\+\_\+add32() function.\hypertarget{a00074_memory}{}\subsubsection{Memory Management}\label{a00074_memory}
In the architectures for which u\+IP is intended, R\+AM is the most scarce resource. With only a few kilobytes of R\+AM available for the T\+C\+P/\+IP stack to use, mechanisms used in traditional T\+C\+P/\+IP cannot be directly applied.

The u\+IP stack does not use explicit dynamic memory allocation. Instead, it uses a single global buffer for holding packets and has a fixed table for holding connection state. The global packet buffer is large enough to contain one packet of maximum size. When a packet arrives from the network, the device driver places it in the global buffer and calls the T\+C\+P/\+IP stack. If the packet contains data, the T\+C\+P/\+IP stack will notify the corresponding application. Because the data in the buffer will be overwritten by the next incoming packet, the application will either have to act immediately on the data or copy the data into a secondary buffer for later processing. The packet buffer will not be overwritten by new packets before the application has processed the data. Packets that arrive when the application is processing the data must be queued, either by the network device or by the device driver. Most single-\/chip Ethernet controllers have on-\/chip buffers that are large enough to contain at least 4 maximum sized Ethernet frames. Devices that are handled by the processor, such as R\+S-\/232 ports, can copy incoming bytes to a separate buffer during application processing. If the buffers are full, the incoming packet is dropped. This will cause performance degradation, but only when multiple connections are running in parallel. This is because u\+IP advertises a very small receiver window, which means that only a single T\+CP segment will be in the network per connection.

In u\+IP, the same global packet buffer that is used for incoming packets is also used for the T\+C\+P/\+IP headers of outgoing data. If the application sends dynamic data, it may use the parts of the global packet buffer that are not used for headers as a temporary storage buffer. To send the data, the application passes a pointer to the data as well as the length of the data to the stack. The T\+C\+P/\+IP headers are written into the global buffer and once the headers have been produced, the device driver sends the headers and the application data out on the network. The data is not queued for retransmissions. Instead, the application will have to reproduce the data if a retransmission is necessary.

The total amount of memory usage for u\+IP depends heavily on the applications of the particular device in which the implementations are to be run. The memory configuration determines both the amount of traffic the system should be able to handle and the maximum amount of simultaneous connections. A device that will be sending large e-\/mails while at the same time running a web server with highly dynamic web pages and multiple simultaneous clients, will require more R\+AM than a simple Telnet server. It is possible to run the u\+IP implementation with as little as 200 bytes of R\+AM, but such a configuration will provide extremely low throughput and will only allow a small number of simultaneous connections.\hypertarget{a00074_api}{}\subsubsection{Application Program Interface (\+A\+P\+I)}\label{a00074_api}
The Application Program Interface (A\+PI) defines the way the application program interacts with the T\+C\+P/\+IP stack. The most commonly used A\+PI for T\+C\+P/\+IP is the B\+SD socket A\+PI which is used in most Unix systems and has heavily influenced the Microsoft Windows Win\+Sock A\+PI. Because the socket A\+PI uses stop-\/and-\/wait semantics, it requires support from an underlying multitasking operating system. Since the overhead of task management, context switching and allocation of stack space for the tasks might be too high in the intended u\+IP target architectures, the B\+SD socket interface is not suitable for our purposes.

u\+IP provides two A\+P\+Is to programmers\+: protosockets, a B\+SD socket-\/like A\+PI without the overhead of full multi-\/threading, and a \char`\"{}raw\char`\"{} event-\/based A\+PI that is nore low-\/level than protosockets but uses less memory.

\begin{DoxySeeAlso}{See also}
psock 

\hyperlink{a00066}{Protothreads}
\end{DoxySeeAlso}
\hypertarget{a00074_rawapi}{}\paragraph{The u\+I\+P raw A\+PI}\label{a00074_rawapi}
The \char`\"{}raw\char`\"{} u\+IP A\+PI uses an event driven interface where the application is invoked in response to certain events. An application running on top of u\+IP is implemented as a C function that is called by u\+IP in response to certain events. u\+IP calls the application when data is received, when data has been successfully delivered to the other end of the connection, when a new connection has been set up, or when data has to be retransmitted. The application is also periodically polled for new data. The application program provides only one callback function; it is up to the application to deal with mapping different network services to different ports and connections. Because the application is able to act on incoming data and connection requests as soon as the T\+C\+P/\+IP stack receives the packet, low response times can be achieved even in low-\/end systems.

u\+IP is different from other T\+C\+P/\+IP stacks in that it requires help from the application when doing retransmissions. Other T\+C\+P/\+IP stacks buffer the transmitted data in memory until the data is known to be successfully delivered to the remote end of the connection. If the data needs to be retransmitted, the stack takes care of the retransmission without notifying the application. With this approach, the data has to be buffered in memory while waiting for an acknowledgment even if the application might be able to quickly regenerate the data if a retransmission has to be made.

In order to reduce memory usage, u\+IP utilizes the fact that the application may be able to regenerate sent data and lets the application take part in retransmissions. u\+IP does not keep track of packet contents after they have been sent by the device driver, and u\+IP requires that the application takes an active part in performing the retransmission. When u\+IP decides that a segment should be retransmitted, it calls the application with a flag set indicating that a retransmission is required. The application checks the retransmission flag and produces the same data that was previously sent. From the application\textquotesingle{}s standpoint, performing a retransmission is not different from how the data originally was sent. Therefore the application can be written in such a way that the same code is used both for sending data and retransmitting data. Also, it is important to note that even though the actual retransmission operation is carried out by the application, it is the responsibility of the stack to know when the retransmission should be made. Thus the complexity of the application does not necessarily increase because it takes an active part in doing retransmissions.\hypertarget{a00074_appevents}{}\subparagraph{Application Events}\label{a00074_appevents}
The application must be implemented as a C function, U\+I\+P\+\_\+\+A\+P\+P\+C\+A\+L\+L(), that u\+IP calls whenever an event occurs. Each event has a corresponding test function that is used to distinguish between different events. The functions are implemented as C macros that will evaluate to either zero or non-\/zero. Note that certain events can happen in conjunction with each other (i.\+e., new data can arrive at the same time as data is acknowledged).\hypertarget{a00074_connstate}{}\subparagraph{The Connection Pointer}\label{a00074_connstate}
When the application is called by u\+IP, the global variable uip\+\_\+conn is set to point to the uip\+\_\+conn structure for the connection that currently is handled, and is called the \char`\"{}current connection\char`\"{}. The fields in the uip\+\_\+conn structure for the current connection can be used, e.\+g., to distinguish between different services, or to check to which IP address the connection is connected. One typical use would be to inspect the uip\+\_\+conn-\/$>$lport (the local T\+CP port number) to decide which service the connection should provide. For instance, an application might decide to act as an H\+T\+TP server if the value of uip\+\_\+conn-\/$>$lport is equal to 80 and act as a T\+E\+L\+N\+ET server if the value is 23.\hypertarget{a00074_recvdata}{}\subparagraph{Receiving Data}\label{a00074_recvdata}
If the u\+IP test function uip\+\_\+newdata() is non-\/zero, the remote host of the connection has sent new data. The uip\+\_\+appdata pointer point to the actual data. The size of the data is obtained through the u\+IP function uip\+\_\+datalen(). The data is not buffered by u\+IP, but will be overwritten after the application function returns, and the application will therefor have to either act directly on the incoming data, or by itself copy the incoming data into a buffer for later processing.\hypertarget{a00074_senddata}{}\subparagraph{Sending Data}\label{a00074_senddata}
When sending data, u\+IP adjusts the length of the data sent by the application according to the available buffer space and the current T\+CP window advertised by the receiver. The amount of buffer space is dictated by the memory configuration. It is therefore possible that all data sent from the application does not arrive at the receiver, and the application may use the uip\+\_\+mss() function to see how much data that actually will be sent by the stack.

The application sends data by using the u\+IP function uip\+\_\+send(). The uip\+\_\+send() function takes two arguments; a pointer to the data to be sent and the length of the data. If the application needs R\+AM space for producing the actual data that should be sent, the packet buffer (pointed to by the uip\+\_\+appdata pointer) can be used for this purpose.

The application can send only one chunk of data at a time on a connection and it is not possible to call uip\+\_\+send() more than once per application invocation; only the data from the last call will be sent.\hypertarget{a00074_rexmitdata}{}\subparagraph{Retransmitting Data}\label{a00074_rexmitdata}
Retransmissions are driven by the periodic T\+CP timer. Every time the periodic timer is invoked, the retransmission timer for each connection is decremented. If the timer reaches zero, a retransmission should be made. As u\+IP does not keep track of packet contents after they have been sent by the device driver, u\+IP requires that the application takes an active part in performing the retransmission. When u\+IP decides that a segment should be retransmitted, the application function is called with the uip\+\_\+rexmit() flag set, indicating that a retransmission is required.

The application must check the uip\+\_\+rexmit() flag and produce the same data that was previously sent. From the application\textquotesingle{}s standpoint, performing a retransmission is not different from how the data originally was sent. Therefor, the application can be written in such a way that the same code is used both for sending data and retransmitting data. Also, it is important to note that even though the actual retransmission operation is carried out by the application, it is the responsibility of the stack to know when the retransmission should be made. Thus the complexity of the application does not necessarily increase because it takes an active part in doing retransmissions.\hypertarget{a00074_closing}{}\subparagraph{Closing Connections}\label{a00074_closing}
The application closes the current connection by calling the uip\+\_\+close() during an application call. This will cause the connection to be cleanly closed. In order to indicate a fatal error, the application might want to abort the connection and does so by calling the uip\+\_\+abort() function.

If the connection has been closed by the remote end, the test function uip\+\_\+closed() is true. The application may then do any necessary cleanups.\hypertarget{a00074_errors}{}\subparagraph{Reporting Errors}\label{a00074_errors}
There are two fatal errors that can happen to a connection, either that the connection was aborted by the remote host, or that the connection retransmitted the last data too many times and has been aborted. u\+IP reports this by calling the application function. The application can use the two test functions uip\+\_\+aborted() and uip\+\_\+timedout() to test for those error conditions.\hypertarget{a00074_polling}{}\subparagraph{Polling}\label{a00074_polling}
When a connection is idle, u\+IP polls the application every time the periodic timer fires. The application uses the test function uip\+\_\+poll() to check if it is being polled by u\+IP.

The polling event has two purposes. The first is to let the application periodically know that a connection is idle, which allows the application to close connections that have been idle for too long. The other purpose is to let the application send new data that has been produced. The application can only send data when invoked by u\+IP, and therefore the poll event is the only way to send data on an otherwise idle connection.\hypertarget{a00074_listen}{}\subparagraph{Listening Ports}\label{a00074_listen}
u\+IP maintains a list of listening T\+CP ports. A new port is opened for listening with the uip\+\_\+listen() function. When a connection request arrives on a listening port, u\+IP creates a new connection and calls the application function. The test function uip\+\_\+connected() is true if the application was invoked because a new connection was created.

The application can check the lport field in the uip\+\_\+conn structure to check to which port the new connection was connected.\hypertarget{a00074_connect}{}\subparagraph{Opening Connections}\label{a00074_connect}
New connections can be opened from within u\+IP by the function uip\+\_\+connect(). This function allocates a new connection and sets a flag in the connection state which will open a T\+CP connection to the specified IP address and port the next time the connection is polled by u\+IP. The uip\+\_\+connect() function returns a pointer to the uip\+\_\+conn structure for the new connection. If there are no free connection slots, the function returns N\+U\+LL.

The function uip\+\_\+ipaddr() may be used to pack an IP address into the two element 16-\/bit array used by u\+IP to represent IP addresses.

Two examples of usage are shown below. The first example shows how to open a connection to T\+CP port 8080 of the remote end of the current connection. If there are not enough T\+CP connection slots to allow a new connection to be opened, the uip\+\_\+connect() function returns N\+U\+LL and the current connection is aborted by uip\+\_\+abort().


\begin{DoxyCode}
\textcolor{keywordtype}{void} connect\_example1\_app(\textcolor{keywordtype}{void}) \{
   \textcolor{keywordflow}{if}(uip\_connect(uip\_conn->ripaddr, HTONS(8080)) == NULL) \{
      uip\_abort();
   \}
\}   
\end{DoxyCode}


The second example shows how to open a new connection to a specific IP address. No error checks are made in this example.


\begin{DoxyCode}
\textcolor{keywordtype}{void} connect\_example2(\textcolor{keywordtype}{void}) \{
   uip\_addr\_t ipaddr;

   uip\_ipaddr(ipaddr, 192,168,0,1);
   uip\_connect(ipaddr, HTONS(8080));
\}
\end{DoxyCode}
\hypertarget{a00074_examples}{}\subsubsection{Examples}\label{a00074_examples}
This section presents a number of very simple u\+IP applications. The u\+IP code distribution contains several more complex applications.\hypertarget{a00074_example1}{}\paragraph{A Very Simple Application}\label{a00074_example1}
This first example shows a very simple application. The application listens for incoming connections on port 1234. When a connection has been established, the application replies to all data sent to it by saying \char`\"{}ok\char`\"{}

The implementation of this application is shown below. The application is initialized with the function called example1\+\_\+init() and the u\+IP callback function is called example1\+\_\+app(). For this application, the configuration variable U\+I\+P\+\_\+\+A\+P\+P\+C\+A\+LL should be defined to be example1\+\_\+app().


\begin{DoxyCode}
\textcolor{keywordtype}{void} example1\_init(\textcolor{keywordtype}{void}) \{
   uip\_listen(HTONS(1234));
\}

\textcolor{keywordtype}{void} example1\_app(\textcolor{keywordtype}{void}) \{
   \textcolor{keywordflow}{if}(uip\_newdata() || uip\_rexmit()) \{
      uip\_send(\textcolor{stringliteral}{"ok\(\backslash\)n"}, 3);
   \}
\}
\end{DoxyCode}


The initialization function calls the u\+IP function uip\+\_\+listen() to register a listening port. The actual application function example1\+\_\+app() uses the test functions uip\+\_\+newdata() and uip\+\_\+rexmit() to determine why it was called. If the application was called because the remote end has sent it data, it responds with an \char`\"{}ok\char`\"{}. If the application function was called because data was lost in the network and has to be retransmitted, it also sends an \char`\"{}ok\char`\"{}. Note that this example actually shows a complete u\+IP application. It is not required for an application to deal with all types of events such as uip\+\_\+connected() or uip\+\_\+timedout().\hypertarget{a00074_example2}{}\paragraph{A More Advanced Application}\label{a00074_example2}
This second example is slightly more advanced than the previous one, and shows how the application state field in the uip\+\_\+conn structure is used.

This application is similar to the first application in that it listens to a port for incoming connections and responds to data sent to it with a single \char`\"{}ok\char`\"{}. The big difference is that this application prints out a welcoming \char`\"{}\+Welcome!\char`\"{} message when the connection has been established.

This seemingly small change of operation makes a big difference in how the application is implemented. The reason for the increase in complexity is that if data should be lost in the network, the application must know what data to retransmit. If the \char`\"{}\+Welcome!\char`\"{} message was lost, the application must retransmit the welcome and if one of the \char`\"{}ok\char`\"{} messages is lost, the application must send a new \char`\"{}ok\char`\"{}.

The application knows that as long as the \char`\"{}\+Welcome!\char`\"{} message has not been acknowledged by the remote host, it might have been dropped in the network. But once the remote host has sent an acknowledgment back, the application can be sure that the welcome has been received and knows that any lost data must be an \char`\"{}ok\char`\"{} message. Thus the application can be in either of two states\+: either in the W\+E\+L\+C\+O\+M\+E-\/\+S\+E\+NT state where the \char`\"{}\+Welcome!\char`\"{} has been sent but not acknowledged, or in the W\+E\+L\+C\+O\+M\+E-\/\+A\+C\+K\+ED state where the \char`\"{}\+Welcome!\char`\"{} has been acknowledged.

When a remote host connects to the application, the application sends the \char`\"{}\+Welcome!\char`\"{} message and sets it\textquotesingle{}s state to W\+E\+L\+C\+O\+M\+E-\/\+S\+E\+NT. When the welcome message is acknowledged, the application moves to the W\+E\+L\+C\+O\+M\+E-\/\+A\+C\+K\+ED state. If the application receives any new data from the remote host, it responds by sending an \char`\"{}ok\char`\"{} back.

If the application is requested to retransmit the last message, it looks at in which state the application is. If the application is in the W\+E\+L\+C\+O\+M\+E-\/\+S\+E\+NT state, it sends a \char`\"{}\+Welcome!\char`\"{} message since it knows that the previous welcome message hasn\textquotesingle{}t been acknowledged. If the application is in the W\+E\+L\+C\+O\+M\+E-\/\+A\+C\+K\+ED state, it knows that the last message was an \char`\"{}ok\char`\"{} message and sends such a message.

The implementation of this application is seen below. This configuration settings for the application is follows after its implementation.


\begin{DoxyCode}
\textcolor{keyword}{struct }example2\_state \{
   \textcolor{keyword}{enum} \{WELCOME\_SENT, WELCOME\_ACKED\} state;
\};

\textcolor{keywordtype}{void} example2\_init(\textcolor{keywordtype}{void}) \{
   uip\_listen(HTONS(2345));
\}

\textcolor{keywordtype}{void} example2\_app(\textcolor{keywordtype}{void}) \{
   \textcolor{keyword}{struct }example2\_state *s;

   s = (\textcolor{keyword}{struct }example2\_state *)uip\_conn->appstate;
   
   \textcolor{keywordflow}{if}(uip\_connected()) \{
      s->state = WELCOME\_SENT;
      uip\_send(\textcolor{stringliteral}{"Welcome!\(\backslash\)n"}, 9);
      \textcolor{keywordflow}{return};
   \} 

   \textcolor{keywordflow}{if}(uip\_acked() && s->state == WELCOME\_SENT) \{
      s->state = WELCOME\_ACKED;
   \}

   \textcolor{keywordflow}{if}(uip\_newdata()) \{
      uip\_send(\textcolor{stringliteral}{"ok\(\backslash\)n"}, 3);
   \}

   \textcolor{keywordflow}{if}(uip\_rexmit()) \{
      \textcolor{keywordflow}{switch}(s->state) \{
      \textcolor{keywordflow}{case} WELCOME\_SENT:
         uip\_send(\textcolor{stringliteral}{"Welcome!\(\backslash\)n"}, 9);
         \textcolor{keywordflow}{break};
      \textcolor{keywordflow}{case} WELCOME\_ACKED:
         uip\_send(\textcolor{stringliteral}{"ok\(\backslash\)n"}, 3);
         \textcolor{keywordflow}{break};
      \}
   \}
\}
\end{DoxyCode}


The configuration for the application\+:


\begin{DoxyCode}
\textcolor{preprocessor}{#define UIP\_APPCALL       example2\_app}
\textcolor{preprocessor}{#define UIP\_APPSTATE\_SIZE sizeof(struct example2\_state)}
\end{DoxyCode}
\hypertarget{a00074_example3}{}\paragraph{Differentiating Between Applications}\label{a00074_example3}
If the system should run multiple applications, one technique to differentiate between them is to use the T\+CP port number of either the remote end or the local end of the connection. The example below shows how the two examples above can be combined into one application.


\begin{DoxyCode}
\textcolor{keywordtype}{void} example3\_init(\textcolor{keywordtype}{void}) \{
   example1\_init();
   example2\_init();   
\}

\textcolor{keywordtype}{void} example3\_app(\textcolor{keywordtype}{void}) \{
   \textcolor{keywordflow}{switch}(uip\_conn->lport) \{
   \textcolor{keywordflow}{case} HTONS(1234):
      example1\_app();
      \textcolor{keywordflow}{break};
   \textcolor{keywordflow}{case} HTONS(2345):
      example2\_app();
      \textcolor{keywordflow}{break};
   \}
\}
\end{DoxyCode}
\hypertarget{a00074_example4}{}\paragraph{Utilizing T\+C\+P Flow Control}\label{a00074_example4}
This example shows a simple application that connects to a host, sends an H\+T\+TP request for a file and downloads it to a slow device such a disk drive. This shows how to use the flow control functions of u\+IP.


\begin{DoxyCode}
\textcolor{keywordtype}{void} example4\_init(\textcolor{keywordtype}{void}) \{
   uip\_ipaddr\_t ipaddr;
   uip\_ipaddr(ipaddr, 192,168,0,1);
   uip\_connect(ipaddr, HTONS(80));
\}

\textcolor{keywordtype}{void} example4\_app(\textcolor{keywordtype}{void}) \{
   \textcolor{keywordflow}{if}(uip\_connected() || uip\_rexmit()) \{
      uip\_send(\textcolor{stringliteral}{"GET /file HTTP/1.0\(\backslash\)r\(\backslash\)nServer:192.186.0.1\(\backslash\)r\(\backslash\)n\(\backslash\)r\(\backslash\)n"},
               48);
      \textcolor{keywordflow}{return};
   \}

   \textcolor{keywordflow}{if}(uip\_newdata()) \{
      device\_enqueue(uip\_appdata, uip\_datalen());
      \textcolor{keywordflow}{if}(device\_queue\_full()) \{
         uip\_stop();
      \}
   \}

   \textcolor{keywordflow}{if}(uip\_poll() && uip\_stopped()) \{
      \textcolor{keywordflow}{if}(!device\_queue\_full()) \{
         uip\_restart();
      \}
   \}
\}
\end{DoxyCode}


When the connection has been established, an H\+T\+TP request is sent to the server. Since this is the only data that is sent, the application knows that if it needs to retransmit any data, it is that request that should be retransmitted. It is therefore possible to combine these two events as is done in the example.

When the application receives new data from the remote host, it sends this data to the device by using the function device\+\_\+enqueue(). It is important to note that this example assumes that this function copies the data into its own buffers. The data in the uip\+\_\+appdata buffer will be overwritten by the next incoming packet.

If the device\textquotesingle{}s queue is full, the application stops the data from the remote host by calling the u\+IP function uip\+\_\+stop(). The application can then be sure that it will not receive any new data until uip\+\_\+restart() is called. The application polling event is used to check if the device\textquotesingle{}s queue is no longer full and if so, the data flow is restarted with uip\+\_\+restart().\hypertarget{a00074_example5}{}\paragraph{A Simple Web Server}\label{a00074_example5}
This example shows a very simple file server application that listens to two ports and uses the port number to determine which file to send. If the files are properly formatted, this simple application can be used as a web server with static pages. The implementation follows.


\begin{DoxyCode}
\textcolor{keyword}{struct }example5\_state \{
   \textcolor{keywordtype}{char} *dataptr;
   \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} dataleft;
\};

\textcolor{keywordtype}{void} example5\_init(\textcolor{keywordtype}{void}) \{
   uip\_listen(HTONS(80));
   uip\_listen(HTONS(81));
\}

\textcolor{keywordtype}{void} example5\_app(\textcolor{keywordtype}{void}) \{
   \textcolor{keyword}{struct }example5\_state *s;
   s = (\textcolor{keyword}{struct }example5\_state)uip\_conn->appstate;
   
   \textcolor{keywordflow}{if}(uip\_connected()) \{
      \textcolor{keywordflow}{switch}(uip\_conn->lport) \{
      \textcolor{keywordflow}{case} HTONS(80):
         s->dataptr = data\_port\_80;
         s->dataleft = datalen\_port\_80;
         \textcolor{keywordflow}{break};
      \textcolor{keywordflow}{case} HTONS(81):
         s->dataptr = data\_port\_81;
         s->dataleft = datalen\_port\_81;
         \textcolor{keywordflow}{break};
      \}
      uip\_send(s->dataptr, s->dataleft);
      \textcolor{keywordflow}{return};      
   \}

   \textcolor{keywordflow}{if}(uip\_acked()) \{
      \textcolor{keywordflow}{if}(s->dataleft < uip\_mss()) \{
         uip\_close();
         \textcolor{keywordflow}{return};
      \}
      s->dataptr += uip\_conn->len;
      s->dataleft -= uip\_conn->len;
      uip\_send(s->dataptr, s->dataleft);      
   \}
\}
\end{DoxyCode}


The application state consists of a pointer to the data that should be sent and the size of the data that is left to send. When a remote host connects to the application, the local port number is used to determine which file to send. The first chunk of data is sent using uip\+\_\+send(). u\+IP makes sure that no more than M\+SS bytes of data is actually sent, even though s-\/$>$dataleft may be larger than the M\+SS.

The application is driven by incoming acknowledgments. When data has been acknowledged, new data can be sent. If there is no more data to send, the connection is closed using uip\+\_\+close().\hypertarget{a00074_example6}{}\paragraph{Structured Application Program Design}\label{a00074_example6}
When writing larger programs using u\+IP it is useful to be able to utilize the u\+IP A\+PI in a structured way. The following example provides a structured design that has showed itself to be useful for writing larger protocol implementations than the previous examples showed here. The program is divided into an u\+IP event handler function that calls seven application handler functions that process new data, act on acknowledged data, send new data, deal with connection establishment or closure events and handle errors. The functions are called newdata(), acked(), senddata(), connected(), closed(), aborted(), and timedout(), and needs to be written specifically for the protocol that is being implemented.

The u\+IP event handler function is shown below.


\begin{DoxyCode}
\textcolor{keywordtype}{void} example6\_app(\textcolor{keywordtype}{void}) \{
  \textcolor{keywordflow}{if}(uip\_aborted()) \{
    aborted();
  \}
  \textcolor{keywordflow}{if}(uip\_timedout()) \{
    timedout();
  \}
  \textcolor{keywordflow}{if}(uip\_closed()) \{
    closed();
  \}
  \textcolor{keywordflow}{if}(uip\_connected()) \{
    connected();
  \}
  \textcolor{keywordflow}{if}(uip\_acked()) \{
    acked();
  \}
  \textcolor{keywordflow}{if}(uip\_newdata()) \{
    newdata();
  \}
  \textcolor{keywordflow}{if}(uip\_rexmit() ||
     uip\_newdata() ||
     uip\_acked() ||
     uip\_connected() ||
     uip\_poll()) \{
    senddata();
  \}
\}
\end{DoxyCode}


The function starts with dealing with any error conditions that might have happened by checking if uip\+\_\+aborted() or uip\+\_\+timedout() are true. If so, the appropriate error function is called. Also, if the connection has been closed, the closed() function is called to the it deal with the event.

Next, the function checks if the connection has just been established by checking if uip\+\_\+connected() is true. The connected() function is called and is supposed to do whatever needs to be done when the connection is established, such as intializing the application state for the connection. Since it may be the case that data should be sent out, the senddata() function is called to deal with the outgoing data.

The following very simple application serves as an example of how the application handler functions might look. This application simply waits for any data to arrive on the connection, and responds to the data by sending out the message \char`\"{}\+Hello world!\char`\"{}. To illustrate how to develop an application state machine, this message is sent in two parts, first the \char`\"{}\+Hello\char`\"{} part and then the \char`\"{}world!\char`\"{} part.


\begin{DoxyCode}
\textcolor{preprocessor}{#define STATE\_WAITING 0}
\textcolor{preprocessor}{#define STATE\_HELLO   1}
\textcolor{preprocessor}{#define STATE\_WORLD   2}

\textcolor{keyword}{struct }example6\_state \{
  uint8\_t state;
  \textcolor{keywordtype}{char} *textptr;
  \textcolor{keywordtype}{int}  textlen;
\};

\textcolor{keyword}{static} \textcolor{keywordtype}{void} aborted(\textcolor{keywordtype}{void}) \{\}
\textcolor{keyword}{static} \textcolor{keywordtype}{void} timedout(\textcolor{keywordtype}{void}) \{\}
\textcolor{keyword}{static} \textcolor{keywordtype}{void} closed(\textcolor{keywordtype}{void}) \{\}

\textcolor{keyword}{static} \textcolor{keywordtype}{void} connected(\textcolor{keywordtype}{void}) \{
  \textcolor{keyword}{struct }example6\_state *s = (\textcolor{keyword}{struct }example6\_state *)uip\_conn->appstate;

  s->state   = STATE\_WAITING;
  s->textlen = 0;
\}

\textcolor{keyword}{static} \textcolor{keywordtype}{void} newdata(\textcolor{keywordtype}{void}) \{
  \textcolor{keyword}{struct }example6\_state *s = (\textcolor{keyword}{struct }example6\_state *)uip\_conn->appstate;

  \textcolor{keywordflow}{if}(s->state == STATE\_WAITING) \{
    s->state   = STATE\_HELLO;
    s->textptr = \textcolor{stringliteral}{"Hello "};
    s->textlen = 6;
  \}
\}

\textcolor{keyword}{static} \textcolor{keywordtype}{void} acked(\textcolor{keywordtype}{void}) \{
  \textcolor{keyword}{struct }example6\_state *s = (\textcolor{keyword}{struct }example6\_state *)uip\_conn->appstate;
  
  s->textlen -= uip\_conn->len;
  s->textptr += uip\_conn->len;
  \textcolor{keywordflow}{if}(s->textlen == 0) \{
    \textcolor{keywordflow}{switch}(s->state) \{
    \textcolor{keywordflow}{case} STATE\_HELLO:
      s->state   = STATE\_WORLD;
      s->textptr = \textcolor{stringliteral}{"world!\(\backslash\)n"};
      s->textlen = 7;
      \textcolor{keywordflow}{break};
    \textcolor{keywordflow}{case} STATE\_WORLD:
      uip\_close();
      \textcolor{keywordflow}{break};
    \}
  \}
\}

\textcolor{keyword}{static} \textcolor{keywordtype}{void} senddata(\textcolor{keywordtype}{void}) \{
  \textcolor{keyword}{struct }example6\_state *s = (\textcolor{keyword}{struct }example6\_state *)uip\_conn->appstate;

  \textcolor{keywordflow}{if}(s->textlen > 0) \{
    uip\_send(s->textptr, s->textlen);
  \}
\}
\end{DoxyCode}


The application state consists of a \char`\"{}state\char`\"{} variable, a \char`\"{}textptr\char`\"{} pointer to a text message and the \char`\"{}textlen\char`\"{} length of the text message. The \char`\"{}state\char`\"{} variable can be either \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+W\+A\+I\+T\+I\+N\+G\char`\"{}, meaning that the application is waiting for data to arrive from the network, \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+H\+E\+L\+L\+O\char`\"{}, in which the application is sending the \char`\"{}\+Hello\char`\"{} part of the message, or \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+W\+O\+R\+L\+D\char`\"{}, in which the application is sending the \char`\"{}world!\char`\"{} message.

The application does not handle errors or connection closing events, and therefore the aborted(), timedout() and closed() functions are implemented as empty functions.

The connected() function will be called when a connection has been established, and in this case sets the \char`\"{}state\char`\"{} variable to be \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+W\+A\+I\+T\+I\+N\+G\char`\"{} and the \char`\"{}textlen\char`\"{} variable to be zero, indicating that there is no message to be sent out.

When new data arrives from the network, the newdata() function will be called by the event handler function. The newdata() function will check if the connection is in the \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+W\+A\+I\+T\+I\+N\+G\char`\"{} state, and if so switches to the \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+H\+E\+L\+L\+O\char`\"{} state and registers a 6 byte long \char`\"{}\+Hello
\char`\"{} message with the connection. This message will later be sent out by the senddata() function.

The acked() function is called whenever data that previously was sent has been acknowleged by the receiving host. This acked() function first reduces the amount of data that is left to send, by subtracting the length of the previously sent data (obtained from \char`\"{}uip\+\_\+conn-\/$>$len\char`\"{}) from the \char`\"{}textlen\char`\"{} variable, and also adjusts the \char`\"{}textptr\char`\"{} pointer accordingly. It then checks if the \char`\"{}textlen\char`\"{} variable now is zero, which indicates that all data now has been successfully received, and if so changes application state. If the application was in the \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+H\+E\+L\+L\+O\char`\"{} state, it switches state to \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+W\+O\+R\+L\+D\char`\"{} and sets up a 7 byte \char`\"{}world!\textbackslash{}n\char`\"{} message to be sent. If the application was in the \char`\"{}\+S\+T\+A\+T\+E\+\_\+\+W\+O\+R\+L\+D\char`\"{} state, it closes the connection.

Finally, the senddata() function takes care of actually sending the data that is to be sent. It is called by the event handler function when new data has been received, when data has been acknowledged, when a new connection has been established, when the connection is polled because of inactivity, or when a retransmission should be made. The purpose of the senddata() function is to optionally format the data that is to be sent, and to call the uip\+\_\+send() function to actually send out the data. In this particular example, the function simply calls uip\+\_\+send() with the appropriate arguments if data is to be sent, after checking if data should be sent out or not as indicated by the \char`\"{}textlen\char`\"{} variable.

It is important to note that the senddata() function never should affect the application state; this should only be done in the acked() and newdata() functions.\hypertarget{a00074_protoimpl}{}\subsubsection{Protocol Implementations}\label{a00074_protoimpl}
The protocols in the T\+C\+P/\+IP protocol suite are designed in a layered fashion where each protocol performs a specific function and the interactions between the protocol layers are strictly defined. While the layered approach is a good way to design protocols, it is not always the best way to implement them. In u\+IP, the protocol implementations are tightly coupled in order to save code space.

This section gives detailed information on the specific protocol implementations in u\+IP.\hypertarget{a00074_ip}{}\paragraph{I\+P -\/-\/-\/ Internet Protocol}\label{a00074_ip}
When incoming packets are processed by u\+IP, the IP layer is the first protocol that examines the packet. The IP layer does a few simple checks such as if the destination IP address of the incoming packet matches any of the local IP address and verifies the IP header checksum. Since there are no IP options that are strictly required and because they are very uncommon, any IP options in received packets are dropped.\hypertarget{a00074_ipreass}{}\subparagraph{I\+P Fragment Reassembly}\label{a00074_ipreass}
IP fragment reassembly is implemented using a separate buffer that holds the packet to be reassembled. An incoming fragment is copied into the right place in the buffer and a bit map is used to keep track of which fragments have been received. Because the first byte of an IP fragment is aligned on an 8-\/byte boundary, the bit map requires a small amount of memory. When all fragments have been reassembled, the resulting IP packet is passed to the transport layer. If all fragments have not been received within a specified time frame, the packet is dropped.

The current implementation only has a single buffer for holding packets to be reassembled, and therefore does not support simultaneous reassembly of more than one packet. Since fragmented packets are uncommon, this ought to be a reasonable decision. Extending the implementation to support multiple buffers would be straightforward, however.\hypertarget{a00074_ipbroadcast}{}\subparagraph{Broadcasts and Multicasts}\label{a00074_ipbroadcast}
IP has the ability to broadcast and multicast packets on the local network. Such packets are addressed to special broadcast and multicast addresses. Broadcast is used heavily in many U\+DP based protocols such as the Microsoft Windows file-\/sharing S\+MB protocol. Multicast is primarily used in protocols used for multimedia distribution such as R\+TP. T\+CP is a point-\/to-\/point protocol and does not use broadcast or multicast packets. u\+IP current supports broadcast packets as well as sending multicast packets. Joining multicast groups (I\+G\+MP) and receiving non-\/local multicast packets is not currently supported.\hypertarget{a00074_icmp}{}\paragraph{I\+C\+M\+P -\/-\/-\/ Internet Control Message Protocol}\label{a00074_icmp}
The I\+C\+MP protocol is used for reporting soft error conditions and for querying host parameters. Its main use is, however, the echo mechanism which is used by the \char`\"{}ping\char`\"{} program.

The I\+C\+MP implementation in u\+IP is very simple as itis restricted to only implement I\+C\+MP echo messages. Replies to echo messages are constructed by simply swapping the source and destination IP addresses of incoming echo requests and rewriting the I\+C\+MP header with the Echo-\/\+Reply message type. The I\+C\+MP checksum is adjusted using standard techniques (see R\+F\+C1624).

Since only the I\+C\+MP echo message is implemented, there is no support for Path M\+TU discovery or I\+C\+MP redirect messages. Neither of these is strictly required for interoperability; they are performance enhancement mechanisms.\hypertarget{a00074_tcp}{}\paragraph{T\+C\+P -\/-\/-\/ Transmission Control Protocol}\label{a00074_tcp}
The T\+CP implementation in u\+IP is driven by incoming packets and timer events. Incoming packets are parsed by T\+CP and if the packet contains data that is to be delivered to the application, the application is invoked by the means of the application function call. If the incoming packet acknowledges previously sent data, the connection state is updated and the application is informed, allowing it to send out new data.\hypertarget{a00074_listeb}{}\subparagraph{Listening Connections}\label{a00074_listeb}
T\+CP allows a connection to listen for incoming connection requests. In u\+IP, a listening connection is identified by the 16-\/bit port number and incoming connection requests are checked against the list of listening connections. This list of listening connections is dynamic and can be altered by the applications in the system.\hypertarget{a00074_slidingwindow}{}\subparagraph{Sliding Window}\label{a00074_slidingwindow}
Most T\+CP implementations use a sliding window mechanism for sending data. Multiple data segments are sent in succession without waiting for an acknowledgment for each segment.

The sliding window algorithm uses a lot of 32-\/bit operations and because 32-\/bit arithmetic is fairly expensive on most 8-\/bit C\+P\+Us, u\+IP does not implement it. Also, u\+IP does not buffer sent packets and a sliding window implementation that does not buffer sent packets will have to be supported by a complex application layer. Instead, u\+IP allows only a single T\+CP segment per connection to be unacknowledged at any given time.

It is important to note that even though most T\+CP implementations use the sliding window algorithm, it is not required by the T\+CP specifications. Removing the sliding window mechanism does not affect interoperability in any way.\hypertarget{a00074_rttest}{}\subparagraph{Round-\/\+Trip Time Estimation}\label{a00074_rttest}
T\+CP continuously estimates the current Round-\/\+Trip Time (R\+TT) of every active connection in order to find a suitable value for the retransmission time-\/out.

The R\+TT estimation in u\+IP is implemented using T\+CP\textquotesingle{}s periodic timer. Each time the periodic timer fires, it increments a counter for each connection that has unacknowledged data in the network. When an acknowledgment is received, the current value of the counter is used as a sample of the R\+TT. The sample is used together with Van Jacobson\textquotesingle{}s standard T\+CP R\+TT estimation function to calculate an estimate of the R\+TT. Karn\textquotesingle{}s algorithm is used to ensure that retransmissions do not skew the estimates.\hypertarget{a00074_rexmit}{}\subparagraph{Retransmissions}\label{a00074_rexmit}
Retransmissions are driven by the periodic T\+CP timer. Every time the periodic timer is invoked, the retransmission timer for each connection is decremented. If the timer reaches zero, a retransmission should be made.

As u\+IP does not keep track of packet contents after they have been sent by the device driver, u\+IP requires that the application takes an active part in performing the retransmission. When u\+IP decides that a segment should be retransmitted, it calls the application with a flag set indicating that a retransmission is required. The application checks the retransmission flag and produces the same data that was previously sent. From the application\textquotesingle{}s standpoint, performing a retransmission is not different from how the data originally was sent. Therefore the application can be written in such a way that the same code is used both for sending data and retransmitting data. Also, it is important to note that even though the actual retransmission operation is carried out by the application, it is the responsibility of the stack to know when the retransmission should be made. Thus the complexity of the application does not necessarily increase because it takes an active part in doing retransmissions.\hypertarget{a00074_flowcontrol}{}\subparagraph{Flow Control}\label{a00074_flowcontrol}
The purpose of T\+CP\textquotesingle{}s flow control mechanisms is to allow communication between hosts with wildly varying memory dimensions. In each T\+CP segment, the sender of the segment indicates its available buffer space. A T\+CP sender must not send more data than the buffer space indicated by the receiver.

In u\+IP, the application cannot send more data than the receiving host can buffer. And application cannot send more data than the amount of bytes it is allowed to send by the receiving host. If the remote host cannot accept any data at all, the stack initiates the zero window probing mechanism.\hypertarget{a00074_congestioncontrol}{}\subparagraph{Congestion Control}\label{a00074_congestioncontrol}
The congestion control mechanisms limit the number of simultaneous T\+CP segments in the network. The algorithms used for congestion control are designed to be simple to implement and require only a few lines of code.

Since u\+IP only handles one in-\/flight T\+CP segment per connection, the amount of simultaneous segments cannot be further limited, thus the congestion control mechanisms are not needed.\hypertarget{a00074_urgdata}{}\subparagraph{Urgent Data}\label{a00074_urgdata}
T\+CP\textquotesingle{}s urgent data mechanism provides an application-\/to-\/application notification mechanism, which can be used by an application to mark parts of the data stream as being more urgent than the normal stream. It is up to the receiving application to interpret the meaning of the urgent data.

In many T\+CP implementations, including the B\+SD implementation, the urgent data feature increases the complexity of the implementation because it requires an asynchronous notification mechanism in an otherwise synchronous A\+PI. As u\+IP already use an asynchronous event based A\+PI, the implementation of the urgent data feature does not lead to increased complexity.\hypertarget{a00074_performance}{}\subsubsection{Performance}\label{a00074_performance}
In T\+C\+P/\+IP implementations for high-\/end systems, processing time is dominated by the checksum calculation loop, the operation of copying packet data and context switching. Operating systems for high-\/end systems often have multiple protection domains for protecting kernel data from user processes and user processes from each other. Because the T\+C\+P/\+IP stack is run in the kernel, data has to be copied between the kernel space and the address space of the user processes and a context switch has to be performed once the data has been copied. Performance can be enhanced by combining the copy operation with the checksum calculation. Because high-\/end systems usually have numerous active connections, packet demultiplexing is also an expensive operation.

A small embedded device does not have the necessary processing power to have multiple protection domains and the power to run a multitasking operating system. Therefore there is no need to copy data between the T\+C\+P/\+IP stack and the application program. With an event based A\+PI there is no context switch between the T\+C\+P/\+IP stack and the applications.

In such limited systems, the T\+C\+P/\+IP processing overhead is dominated by the copying of packet data from the network device to host memory, and checksum calculation. Apart from the checksum calculation and copying, the T\+CP processing done for an incoming packet involves only updating a few counters and flags before handing the data over to the application. Thus an estimate of the C\+PU overhead of our T\+C\+P/\+IP implementations can be obtained by calculating the amount of C\+PU cycles needed for the checksum calculation and copying of a maximum sized packet.\hypertarget{a00074_delack}{}\paragraph{The Impact of Delayed Acknowledgments}\label{a00074_delack}
Most T\+CP receivers implement the delayed acknowledgment algorithm for reducing the number of pure acknowledgment packets sent. A T\+CP receiver using this algorithm will only send acknowledgments for every other received segment. If no segment is received within a specific time-\/frame, an acknowledgment is sent. The time-\/frame can be as high as 500 ms but typically is 200 ms.

A T\+CP sender such as u\+IP that only handles a single outstanding T\+CP segment will interact poorly with the delayed acknowledgment algorithm. Because the receiver only receives a single segment at a time, it will wait as much as 500 ms before an acknowledgment is sent. This means that the maximum possible throughput is severely limited by the 500 ms idle time.

Thus the maximum throughput equation when sending data from u\+IP will be \$p = s / (t + t\+\_\+d)\$ where \$s\$ is the segment size and \$t\+\_\+d\$ is the delayed acknowledgment timeout, which typically is between 200 and 500 ms. With a segment size of 1000 bytes, a round-\/trip time of 40 ms and a delayed acknowledgment timeout of 200 ms, the maximum throughput will be 4166 bytes per second. With the delayed acknowledgment algorithm disabled at the receiver, the maximum throughput would be 25000 bytes per second.

It should be noted, however, that since small systems running u\+IP are not very likely to have large amounts of data to send, the delayed acknowledgmen t throughput degradation of u\+IP need not be very severe. Small amounts of data sent by such a system will not span more than a single T\+CP segment, and would therefore not be affected by the throughput degradation anyway.

The maximum throughput when u\+IP acts as a receiver is not affected by the delayed acknowledgment throughput degradation.

\begin{DoxyNote}{Note}
The uipsplit module implements a hack that overcomes the problems with the delayed acknowledgment throughput degradation. 
\end{DoxyNote}
